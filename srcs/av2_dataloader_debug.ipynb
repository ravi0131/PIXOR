{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from utils import plot_bev, get_points_in_a_rotated_box, plot_label_map, trasform_label2metric\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from av2.datasets.sensor.av2_sensor_dataloader import  AV2SensorDataLoader\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "AV2_PATH = os.path.join(os.path.expanduser('~'), 'buni','dataset','av2')\n",
    "\n",
    "class AV2(Dataset):\n",
    "\n",
    "    geometry = {\n",
    "        'L1': -40.0,\n",
    "        'L2': 40.0,\n",
    "        'W1': 0.0,\n",
    "        'W2': 70.0,\n",
    "        'H1': -2.5,\n",
    "        'H2': 1.0,\n",
    "        'input_shape': (800, 700, 36),\n",
    "        'label_shape': (200, 175, 7)\n",
    "    }\n",
    "\n",
    "    target_mean = np.array([0.008, 0.001, 0.202, 0.2, 0.43, 1.368])\n",
    "    target_std_dev = np.array([0.866, 0.5, 0.954, 0.668, 0.09, 0.111])\n",
    "\n",
    "\n",
    "    def __init__(self,train=True):\n",
    "        self.dataset_api = None\n",
    "        self.train = train\n",
    "        if train:\n",
    "            train_path = Path(os.path.join(AV2_PATH, 'train'))\n",
    "            self.av2_api = AV2SensorDataLoader(data_dir=train_path, labels_dir=train_path)\n",
    "        else:\n",
    "            test_path = Path(os.path.join(AV2_PATH, 'test'))\n",
    "            self.av2_api = AV2SensorDataLoader(data_dir=test_path, labels_dir=test_path)\n",
    "        \n",
    "        self.scenes = self.av2_api.get_log_ids()\n",
    "        self.global_to_scene_frame = []  # List mapping global index to (scene_id, frame_idx)\n",
    "        self.total_frames = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_frames\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        scan = self.load_velo_scan(item)\n",
    "        scan = self.lidar_preprocess(scan)\n",
    "        scan = torch.from_numpy(scan)\n",
    "        \n",
    "        label_map, _ = self.get_label(item)\n",
    "        self.reg_target_transform(label_map)\n",
    "        label_map = torch.from_numpy(label_map)\n",
    "        \n",
    "        scan = scan.permute(2, 0, 1)\n",
    "        label_map = label_map.permute(2, 0, 1)\n",
    "        return scan, label_map, item\n",
    "\n",
    "    # def __getitem__(self, item):\n",
    "    #     start = time.time()\n",
    "    #     print(f\"Fetching item: {item}\")\n",
    "\n",
    "    #     # Step 1: Load the Velodyne scan\n",
    "    #     t1 = time.time()\n",
    "    #     scan = self.load_velo_scan(item)\n",
    "    #     t2 = time.time()\n",
    "    #     print(f\"Time taken for load_velo_scan (item {item}): {t2 - t1:.2f} seconds\")\n",
    "\n",
    "    #     # Step 2: Preprocess the scan\n",
    "    #     t3 = time.time()\n",
    "    #     scan = self.lidar_preprocess(scan)\n",
    "    #     t4 = time.time()\n",
    "    #     print(f\"Time taken for lidar_preprocess (item {item}): {t4 - t3:.2f} seconds\")\n",
    "\n",
    "    #     # Step 3: Get the label\n",
    "    #     t5 = time.time()\n",
    "    #     label_map, _ = self.get_label(item)\n",
    "    #     t6 = time.time()\n",
    "    #     print(f\"Time taken for get_label (item {item}): {t6 - t5:.2f} seconds\")\n",
    "\n",
    "    #     # Step 4: Apply regression target transform\n",
    "    #     t7 = time.time()\n",
    "    #     self.reg_target_transform(label_map)\n",
    "    #     t8 = time.time()\n",
    "    #     print(f\"Time taken for reg_target_transform (item {item}): {t8 - t7:.2f} seconds\")\n",
    "\n",
    "    #     # Step 5: Final tensor conversions\n",
    "    #     scan = torch.from_numpy(scan).permute(2, 0, 1)\n",
    "    #     label_map = torch.from_numpy(label_map).permute(2, 0, 1)\n",
    "\n",
    "    #     end = time.time()\n",
    "    #     print(f\"Total time taken for __getitem__ (item {item}): {end - start:.2f} seconds\")\n",
    "        \n",
    "    #     return scan, label_map, item\n",
    "\n",
    "    def reg_target_transform(self, label_map: np.ndarray):\n",
    "        '''\n",
    "        Inputs are numpy arrays (not tensors!)\n",
    "        :param label_map: [200 * 175 * 7] label tensor\n",
    "        :return: normalized regression map for all non_zero classification locations\n",
    "        '''\n",
    "        cls_map = label_map[..., 0]\n",
    "        reg_map = label_map[..., 1:]\n",
    "\n",
    "        index = np.nonzero(cls_map)\n",
    "        reg_map[index] = (reg_map[index] - self.target_mean)/self.target_std_dev\n",
    "        \n",
    "    def get_corners(self, bbox: List[float]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        return the 4 corners of the bounding box in the bird's eye view\n",
    "        \n",
    "        Args:\n",
    "            bbox:  list of the bounding box parameters of shape (5)\n",
    "        \n",
    "        Returns:\n",
    "            bev_corners: [4 * 2] numpy array of the 4 corners' (x, y)\n",
    "            reg_target: [6] numpy array of the regression targets  \n",
    "        \"\"\"\n",
    "        x, y, l, w, yaw = bbox\n",
    "        \n",
    "        bev_corners = np.zeros((4, 2), dtype=np.float32)\n",
    "        # rear left\n",
    "        bev_corners[0, 0] = x - l/2 * np.cos(yaw) - w/2 * np.sin(yaw)\n",
    "        bev_corners[0, 1] = y - l/2 * np.sin(yaw) + w/2 * np.cos(yaw)\n",
    "\n",
    "        # rear right\n",
    "        bev_corners[1, 0] = x - l/2 * np.cos(yaw) + w/2 * np.sin(yaw)\n",
    "        bev_corners[1, 1] = y - l/2 * np.sin(yaw) - w/2 * np.cos(yaw)\n",
    "\n",
    "        # front right\n",
    "        bev_corners[2, 0] = x + l/2 * np.cos(yaw) + w/2 * np.sin(yaw)\n",
    "        bev_corners[2, 1] = y + l/2 * np.sin(yaw) - w/2 * np.cos(yaw)\n",
    "\n",
    "        # front left\n",
    "        bev_corners[3, 0] = x + l/2 * np.cos(yaw) - w/2 * np.sin(yaw)\n",
    "        bev_corners[3, 1] = y + l/2 * np.sin(yaw) + w/2 * np.cos(yaw)\n",
    "\n",
    "        reg_target = [np.cos(yaw), np.sin(yaw), x, y, w, l]\n",
    "\n",
    "        return bev_corners, reg_target\n",
    "\n",
    "\n",
    "    def update_label_map(self, map: np.ndarray, bev_corners: np.ndarray, reg_target: np.ndarray):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            map: [200 * 175 * 7] numpy array\n",
    "            bev_corners: [4 * 2] numpy array of the 4 corners' (x, y)\n",
    "            reg_target: [6] numpy array of the regression targets\n",
    "        \n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        label_corners = (bev_corners / 4 ) / 0.1\n",
    "        label_corners[:, 1] += self.geometry['label_shape'][0] / 2\n",
    "\n",
    "        points = get_points_in_a_rotated_box(label_corners, self.geometry['label_shape'])\n",
    "\n",
    "        for p in points:\n",
    "            label_x = p[0]\n",
    "            label_y = p[1]\n",
    "            metric_x, metric_y = trasform_label2metric(np.array(p))\n",
    "            actual_reg_target = np.copy(reg_target)\n",
    "            actual_reg_target[2] = reg_target[2] - metric_x\n",
    "            actual_reg_target[3] = reg_target[3] - metric_y\n",
    "            actual_reg_target[4] = np.log(reg_target[4])\n",
    "            actual_reg_target[5] = np.log(reg_target[5])\n",
    "\n",
    "            map[label_y, label_x, 0] = 1.0\n",
    "            map[label_y, label_x, 1:7] = actual_reg_target\n",
    "\n",
    "\n",
    "    def get_label(self, index):\n",
    "        '''\n",
    "        :param i: the ith velodyne scan in the train/val set\n",
    "        :return: label map: <--- This is the learning target\n",
    "                a tensor of shape 800 * 700 * 7 representing the expected output\n",
    "\n",
    "\n",
    "                label_list: <--- Intended for evaluation metrics & visualization\n",
    "                a list of length n; n =  number of cars + (truck+van+tram+dontcare) in the frame\n",
    "                each entry is another list, where the first element of this list indicates if the object\n",
    "                is a car or one of the 'dontcare' (truck,van,etc) object\n",
    "\n",
    "        '''\n",
    "        if self.train:\n",
    "            label_path = os.path.join(os.path.expanduser('~'),'buni', 'output-data','av2','bbox-estimation')\n",
    "        else:\n",
    "            raise NotImplementedError(\"Labels for test set are not available\")\n",
    "        log_id, frame_id = self.global_to_scene_frame[index]\n",
    "        print(f\"get_label() called => log_id is {log_id} and frame_id is {frame_id}\")\n",
    "        label_map = np.zeros(self.geometry['label_shape'], dtype=np.float32)\n",
    "        label_list = []\n",
    "      \n",
    "        labels_df = pd.read_feather(os.path.join(label_path, log_id, str(frame_id) + '.feather'))\n",
    "        \n",
    "        for index, row in labels_df.iterrows():\n",
    "            #convert row into a list\n",
    "            row = row.tolist()\n",
    "            corners, reg_target = self.get_corners(row)\n",
    "            self.update_label_map(label_map, corners, reg_target)\n",
    "            label_list.append(corners)\n",
    "        return label_map, label_list\n",
    "\n",
    "    def get_rand_velo(self):\n",
    "        import random\n",
    "        rand_v = random.choice(self.velo)\n",
    "        print(\"A Velodyne Scan has shape \", rand_v.shape)\n",
    "        return random.choice(self.velo)\n",
    "\n",
    "    def load_velo_scan(self, item: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Helper method to get a lidar frame\n",
    "        \n",
    "        Args:\n",
    "            item: The index of the frame to get\n",
    "        \n",
    "        Returns:\n",
    "            A numpy array of shape (36, 800, 700) containing the voxelized lidar scan\n",
    "        \"\"\"\n",
    "        log_id, frame_id = self.global_to_scene_frame[item]\n",
    "        \n",
    "        frame_path = self.av2_api.get_lidar_fpath(log_id,frame_id)\n",
    "        lidar_frame_feather = pd.read_feather(frame_path)\n",
    "        scan =  lidar_frame_feather[['x', 'y', 'z', 'intensity']].values\n",
    "        \n",
    "        return scan\n",
    "\n",
    "    \n",
    "    def load_velo(self):\n",
    "        \"\"\"Precompute mapping to fill the global_to_scene_frame list\"\"\"\n",
    "        for scene_id in self.scenes:\n",
    "            frames = self.av2_api.get_ordered_log_lidar_timestamps(scene_id)\n",
    "            num_frames = len(frames)\n",
    "            for frame_idx in range(num_frames):\n",
    "                self.global_to_scene_frame.append((scene_id, frames[frame_idx]))\n",
    "        self.global_to_scene_frame = self.global_to_scene_frame[::10] # select every 10th sequence to speed up training in av2\n",
    "        self.total_frames = len(self.global_to_scene_frame)  \n",
    "        print(f\"Total frames: {self.total_frames}\")\n",
    "        print(\"Done pre-computing the mapping\")\n",
    "\n",
    "    def point_in_roi(self, point):\n",
    "        if (point[0] - self.geometry['W1']) < 0.01 or (self.geometry['W2'] - point[0]) < 0.01:\n",
    "            return False\n",
    "        if (point[1] - self.geometry['L1']) < 0.01 or (self.geometry['L2'] - point[1]) < 0.01:\n",
    "            return False\n",
    "        if (point[2] - self.geometry['H1']) < 0.01 or (self.geometry['H2'] - point[2]) < 0.01:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def passthrough(self, velo):\n",
    "        \"\"\"\n",
    "        Helper method to filter out points that are not in the region of interest\n",
    "        \n",
    "        Args:\n",
    "            velo: A numpy array of shape (n, 4) containing the lidar scan\n",
    "            Columns => x, y, z, intensity\n",
    "        \n",
    "        Returns:\n",
    "            A numpy array of shape (n, 4) containing the lidar scan\n",
    "        \"\"\"\n",
    "        geom = self.geometry\n",
    "        q = (geom['W1'] < velo[:, 0]) * (velo[:, 0] < geom['W2']) * \\\n",
    "            (geom['L1'] < velo[:, 1]) * (velo[:, 1] < geom['L2']) * \\\n",
    "            (geom['H1'] < velo[:, 2]) * (velo[:, 2] < geom['H2'])\n",
    "        indices = np.where(q)[0]\n",
    "        return velo[indices, :]\n",
    "\n",
    "    def lidar_preprocess(self, scan: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Voxelizes the lidar scan\n",
    "        \n",
    "        Args:\n",
    "            scan: A numpy array of shape (n, 4) containing the lidar scan\n",
    "            Columns => x, y, z, intensity\n",
    "        \n",
    "        Returns:\n",
    "            A numpy array of shape (36, 800, 700) containing the voxelized lidar scan\n",
    "        \"\"\"\n",
    "        velo_processed = np.zeros(self.geometry['input_shape'], dtype=np.float32)\n",
    "        intensity_map_count = np.zeros((velo_processed.shape[0], velo_processed.shape[1]))\n",
    "        velo = self.passthrough(scan)\n",
    "        for i in range(velo.shape[0]):\n",
    "            x = int((velo[i, 1]-self.geometry['L1']) / 0.1)\n",
    "            y = int((velo[i, 0]-self.geometry['W1']) / 0.1)\n",
    "            z = int((velo[i, 2]-self.geometry['H1']) / 0.1)\n",
    "            velo_processed[x, y, z] = 1\n",
    "            velo_processed[x, y, -1] += velo[i, 3]\n",
    "            intensity_map_count[x, y] += 1\n",
    "        velo_processed[:, :, -1] = np.divide(velo_processed[:, :, -1],  intensity_map_count,\n",
    "                                             where=intensity_map_count != 0)\n",
    "        return velo_processed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size, use_npy, geometry=None):\n",
    "    train_dataset = AV2(train=True)\n",
    "    if geometry is not None:\n",
    "        train_dataset.geometry = geometry\n",
    "    train_dataset.load_velo()\n",
    "    train_data_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=0)\n",
    "    \n",
    "    val_dataset = AV2(train=False)\n",
    "    if geometry is not None:\n",
    "        val_dataset.geometry = geometry\n",
    "    val_dataset.load_velo()\n",
    "    val_data_loader = DataLoader(val_dataset, shuffle=False, batch_size=batch_size * 4, num_workers=0)\n",
    "    print(f\"Total frames in train dataset: {len(train_dataset)}\")\n",
    "    print(f\"Total frames in validation dataset: {len(val_dataset)}\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    return train_data_loader, val_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 52\n",
      "Done pre-computing the mapping\n",
      "Total frames: 36\n",
      "Done pre-computing the mapping\n",
      "Total frames in train dataset: 52\n",
      "Total frames in validation dataset: 36\n",
      "------------------------------------------------------------------\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968522259997000\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968337160012000\n",
      "get_label() called => log_id is ff6adc87-5f47-32f7-b36a-546453c0e332 and frame_id is 315968459459861000\n",
      "0.8609945774078369\n",
      "Entry 0\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968523259956000\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968526259834000\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968538260009000\n",
      "0.8969871997833252\n",
      "Entry 1\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968537260049000\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968338159969000\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968346159624000\n",
      "0.8155865669250488\n",
      "Entry 2\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968347160243000\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968339159926000\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968536260090000\n",
      "0.8500001430511475\n",
      "Entry 3\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "get_label() called => log_id is ff6adc87-5f47-32f7-b36a-546453c0e332 and frame_id is 315968457459935000\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968527259793000\n",
      "get_label() called => log_id is ff6adc87-5f47-32f7-b36a-546453c0e332 and frame_id is 315968458459899000\n",
      "0.910560131072998\n",
      "Entry 4\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968343159753000\n",
      "get_label() called => log_id is ff52c01e-3d7b-32b1-b6a1-bcff3459ccdd and frame_id is 315968345159666000\n",
      "get_label() called => log_id is ff8e7fdb-1073-3592-ba5e-8111bc3ce48b and frame_id is 315968535260131000\n",
      "0.8655238151550293\n",
      "Entry 5\n",
      "Input shape: torch.Size([3, 36, 800, 700])\n",
      "Label Map shape torch.Size([3, 7, 200, 175])\n",
      "average preprocess time per image 0.28886957963307697\n",
      "Finish testing train dataloader\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # npy average time 0.31s\n",
    "    # c++ average time 0.08s 4 workers\n",
    "    batch_size = 3\n",
    "    train_data_loader, val_data_loader = get_data_loader(batch_size, False)\n",
    "    times = []\n",
    "    tic = time.time()\n",
    "    for i, (input, label_map, item) in enumerate(train_data_loader):\n",
    "        toc = time.time()\n",
    "        print(toc - tic)\n",
    "        times.append(toc-tic)\n",
    "        tic = time.time()\n",
    "        print(\"Entry\", i)\n",
    "        print(\"Input shape:\", input.shape)\n",
    "        print(\"Label Map shape\", label_map.shape)\n",
    "        if i == 5:\n",
    "            break\n",
    "    print(\"average preprocess time per image\", np.mean(times)/batch_size)    \n",
    "\n",
    "    print(\"Finish testing train dataloader\")\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
